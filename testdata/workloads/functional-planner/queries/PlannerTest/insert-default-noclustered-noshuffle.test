# HBASE; EXPECT: Default INSERT hints should be ignored;
insert into functional_hbase.alltypes select * from functional_hbase.alltypes
---- PLAN
WRITE TO HBASE table=functional_hbase.alltypes
|
00:SCAN HBASE [functional_hbase.alltypes]
   row-size=80B cardinality=14.30K
---- DISTRIBUTEDPLAN
WRITE TO HBASE table=functional_hbase.alltypes
|
00:SCAN HBASE [functional_hbase.alltypes]
   row-size=80B cardinality=14.30K
====
# KUDU; DEFAULT: NOCLUSTERED, NOSHUFFLE; EXPECT: NO PARTIAL SORT, NO EXCHANGE;
upsert into functional_kudu.alltypes  select * from functional.alltypes
---- PLAN
UPSERT INTO KUDU [functional_kudu.alltypes]
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
---- DISTRIBUTEDPLAN
UPSERT INTO KUDU [functional_kudu.alltypes]
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
====
# PARTITIONED; DEFAULT: NOCLUSTERED, NOSHUFFLE; EXPECT: NO SORT, NO EXCHANGE;
insert into table functional.alltypes partition(year, month)
select * from functional.alltypes
---- PLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(functional.alltypes.year,functional.alltypes.month)]
|  partitions=24
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
---- DISTRIBUTEDPLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(functional.alltypes.year,functional.alltypes.month)]
|  partitions=24
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
====
# NON-PARTITIONED; DEFAULT: NOCLUSTERED, NOSHUFFLE; EXPECT: NO SORT, NO EXCHANGE;
insert into table functional.alltypesnopart select * from functional.alltypesnopart
---- PLAN
WRITE TO HDFS [functional.alltypesnopart, OVERWRITE=false]
|  partitions=1
|
00:SCAN HDFS [functional.alltypesnopart]
   HDFS partitions=1/1 files=0 size=0B
   row-size=72B cardinality=0
---- DISTRIBUTEDPLAN
WRITE TO HDFS [functional.alltypesnopart, OVERWRITE=false]
|  partitions=1
|
00:SCAN HDFS [functional.alltypesnopart]
   HDFS partitions=1/1 files=0 size=0B
   row-size=72B cardinality=0
====
# PARTITIONED; DEFAULT: NOCLUSTERED, NOSHUFFLE; PLAN HINT: CLUSTERED; EXPECT: SORT, EXCHANGE;
insert into table functional.alltypes partition(year, month) /* +clustered */
select * from functional.alltypes
---- PLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=24
|
01:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  row-size=89B cardinality=7.30K
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
---- DISTRIBUTEDPLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=24
|
02:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  row-size=89B cardinality=7.30K
|
01:EXCHANGE [HASH(functional.alltypes.year,functional.alltypes.month)]
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
====
# PARTITIONED; DEFAULT: NOCLUSTERED, NOSHUFFLE; PLAN HINT: SHUFFLE; EXPECT: SORT, EXCHANGE;
insert into table functional.alltypes partition(year, month) /* +shuffle */
select * from functional.alltypes
---- PLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=24
|
01:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  row-size=89B cardinality=7.30K
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
---- DISTRIBUTEDPLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=24
|
02:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  row-size=89B cardinality=7.30K
|
01:EXCHANGE [HASH(functional.alltypes.year,functional.alltypes.month)]
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
====
# PARTITIONED; DEFAULT: NOCLUSTERED, NOSHUFFLE; PLAN HINT: CLUSTERED, SHUFFLE; EXPECT: SORT, EXCHANGE;
insert into table functional.alltypes partition(year, month) /* +clustered,shuffle */
select * from functional.alltypes
---- PLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=24
|
01:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  row-size=89B cardinality=7.30K
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
---- DISTRIBUTEDPLAN
WRITE TO HDFS [functional.alltypes, OVERWRITE=false, PARTITION-KEYS=(year,month)]
|  partitions=24
|
02:SORT
|  order by: year ASC NULLS LAST, month ASC NULLS LAST
|  row-size=89B cardinality=7.30K
|
01:EXCHANGE [HASH(functional.alltypes.year,functional.alltypes.month)]
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
====
# KUDU; DEFAULT: NOCLUSTERED, NOSHUFFLE; PLAN HINT: CLUSTERED, SHUFFLE; EXPECT: SORT, EXCHANGE;
upsert into functional_kudu.alltypes /* +clustered,shuffle */ select * from functional.alltypes
---- PLAN
UPSERT INTO KUDU [functional_kudu.alltypes]
|
01:PARTIAL SORT
|  order by: KuduPartition(functional.alltypes.id) ASC NULLS LAST, id ASC NULLS LAST
|  row-size=93B cardinality=7.30K
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
---- DISTRIBUTEDPLAN
UPSERT INTO KUDU [functional_kudu.alltypes]
|
02:PARTIAL SORT
|  order by: KuduPartition(functional.alltypes.id) ASC NULLS LAST, id ASC NULLS LAST
|  row-size=93B cardinality=7.30K
|
01:EXCHANGE [KUDU(KuduPartition(functional.alltypes.id))]
|
00:SCAN HDFS [functional.alltypes]
   HDFS partitions=24/24 files=24 size=478.45KB
   row-size=89B cardinality=7.30K
====
